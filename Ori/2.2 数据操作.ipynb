{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aboriginal-notification",
   "metadata": {},
   "source": [
    "# 2.2 数据操作\n",
    "\n",
    "开始我学习Dive-into-DL-PyTorch这个材料。\n",
    "我计划把这些代码过一遍，这样对于DL会有更明确的认识。😂之前自己太弱了。\n",
    "我计划每个小结都做一个notebook，在第一节用markdown写下全部的知识点，也方便自己和其他人看。\n",
    "\n",
    "1. pytorch的安装\n",
    "2. 创建tensor\n",
    "   1. **空**: torch.empty(5,3,dtype=torch.long)\n",
    "   2. **赋值为1**: torch.ones(5,3)\n",
    "   3. **赋值为0**: torch.zeros(5.3)\n",
    "   4. **常用dtype**: torch.float (float32), torch.double  (float64), torch.int (int32), torch.long (int64), torch.bool (boolean)\n",
    "3. numpy与tensor互转\n",
    "   1. **tensor转numpy（共享data）:** x=torch.ones(5,3)  x.numpy()即可转换\n",
    "   2. **numpy转tensor（不共享data）**: torch.tensor([1,2,3]) 这样转换不会共享data，也就是拷贝一份\n",
    "   3. **numpy转tensor（共享data**）: torch.from_numpy(np.ones(5)) 这样转换会共享data\n",
    "4. 计算操作\n",
    "   1. 加法：x+y 或 torch.add(x,y)\n",
    "   2. 切片: x[1:,:-1] 类似numpy\n",
    "   3. 改变形状：x.view(3，5) ，x.view(-1，5)  **这种方法共享data**\n",
    "   4. broadcast原理：两个tensor的shape不同，直接相加会进行broadcast，我的理解是维度的并集\n",
    "   5. 其他操作见：https://pytorch.org/docs/stable/tensors.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-business",
   "metadata": {},
   "source": [
    "## 1. pytorch的安装\n",
    "\n",
    "pytorch的安装：\n",
    "https://pytorch.org/\n",
    "\n",
    "选择对应的版本：\n",
    "\n",
    "![install.png](https://pic.atlasbioinfo.com//blog/20210222/Snipaste_2021-02-22_09-53-44.png)\n",
    "\n",
    "## 2. 创建tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beautiful-priest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7957688336701796208, 8319958742476218724, 7521981625659912239],\n",
       "        [8392862729398479919, 8299912210326384488, 7738135719178499177],\n",
       "        [8245937189886977889, 7795557684927752291, 6874854174328382057],\n",
       "        [3109858083190698083, 3689686583958992944, 3991939109057404969],\n",
       "        [3775814413465248358,               23859,                   0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 2.2.1 创建tensor\n",
    "import torch\n",
    "#空tensor\n",
    "torch.empty(5,3,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-recorder",
   "metadata": {},
   "source": [
    "### Torch中的dtype\n",
    "\n",
    "| Data type | dtype |\n",
    "| :---- | ----: |\n",
    "| 32-bit floating point | torch.float32 or torch.float |\n",
    "| 64-bit floating point | torch.float64 or torch.double |\n",
    "| 64-bit complex | torch.complex64 or torch.cfloat |\n",
    "| 128-bit complex | torch.complex128 or torch.cdouble |\n",
    "| 16-bit floating point 1 | torch.float16 or torch.half |\n",
    "| 16-bit floating point 2 | torch.bfloat16 |\n",
    "| 8-bit integer (unsigned) | torch.uint8 |\n",
    "| 8-bit integer (signed) | torch.int8 |\n",
    "| 16-bit integer (signed) | torch.int16 or torch.short |\n",
    "| 32-bit integer (signed) | torch.int32 or torch.int |\n",
    "| 64-bit integer (signed) | torch.int64 or torch.long |\n",
    "| Boolean | torch.bool |\n",
    "\n",
    "估计常用的：\n",
    "* torch.float\n",
    "* torch.double\n",
    "* torch.int\n",
    "* torch.long\n",
    "* torch.bool\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "micro-postage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4599, 0.7451, 0.6156],\n",
      "        [0.3356, 0.2274, 0.4664],\n",
      "        [0.9546, 0.7263, 0.5476],\n",
      "        [0.5117, 0.4726, 0.4385],\n",
      "        [0.6074, 0.3535, 0.2718]])\n",
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "#随机tensor\n",
    "import torch\n",
    "randExample=torch.rand(5,3)\n",
    "zeroExample = torch.zeros(5, 4, dtype=torch.long)\n",
    "print(randExample)\n",
    "print(zeroExample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "colored-heading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "x.new_ones(5,3)\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# 用tensor转换\n",
    "arr=[[1,2,3],[1,2,3],[1,2,3]]\n",
    "x = torch.tensor(arr)\n",
    "print(x)\n",
    "\n",
    "print(\"x.new_ones(5,3)\")\n",
    "print(x.new_ones(5,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "placed-drove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 查看数据维度\n",
    "print(x.shape)\n",
    "print(x.size())\n",
    "print(x.new_ones(5,3).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-reasoning",
   "metadata": {},
   "source": [
    "### 其他pytorch的构造函数\n",
    "\n",
    "| 函数 | 功能 |\n",
    "| :---- | :---- |\n",
    "| Tensor(\\*sizes) | 基础构造函数 |\n",
    "| tensor(data,) | 类似np.array的构造函数 |\n",
    "| ones(\\*sizes) | 全1Tensor |\n",
    "| zeros(\\*sizes) | 全0Tensor |\n",
    "| eye(\\*sizes) | 对角线为1，其他为0 |\n",
    "| arange(s,e,step) | 从s到e，步长为step |\n",
    "| linspace(s,e,steps) | 从s到e，均匀切分成steps份 |\n",
    "| rand/randn(\\*sizes) | 均匀\\/标准分布 |\n",
    "| normal(mean,std)/uniform(from,to) | 正态分布/均匀分布 |\n",
    "| randperm(m) | 随机排列 |\n",
    "\n",
    "## 算术操作\n",
    "\n",
    "[pytorch文档，100多种线代计算操作](https://pytorch.org/docs/stable/tensors.html)\n",
    "\n",
    "### 加法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "built-animation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1406, 0.2201, 0.9098],\n",
      "        [0.7349, 0.1998, 0.6482],\n",
      "        [0.6419, 0.3224, 0.9947],\n",
      "        [0.4533, 0.3280, 0.2317],\n",
      "        [0.6811, 0.5898, 0.2982]])\n",
      "tensor([[0.1433, 0.8546, 0.0953],\n",
      "        [0.7631, 0.7208, 0.3683],\n",
      "        [0.0098, 0.5418, 0.1683],\n",
      "        [0.2717, 0.9358, 0.3943],\n",
      "        [0.5012, 0.1841, 0.6279]])\n",
      "tensor([[0.2839, 1.0747, 1.0051],\n",
      "        [1.4980, 0.9206, 1.0165],\n",
      "        [0.6518, 0.8641, 1.1630],\n",
      "        [0.7251, 1.2638, 0.6260],\n",
      "        [1.1823, 0.7739, 0.9261]])\n",
      "tensor([[0.2839, 1.0747, 1.0051],\n",
      "        [1.4980, 0.9206, 1.0165],\n",
      "        [0.6518, 0.8641, 1.1630],\n",
      "        [0.7251, 1.2638, 0.6260],\n",
      "        [1.1823, 0.7739, 0.9261]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(5,3)\n",
    "y = torch.rand(5, 3)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x + y)\n",
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-tiger",
   "metadata": {},
   "source": [
    "** 注意，tensor赋值是共享内存的，也就是赋值为内存地址，因此改变一个原有的也会被改变 **\n",
    "```python\n",
    "print(x)\n",
    "y=x\n",
    "y+=1\n",
    "print(x)\n",
    "```\n",
    "Output:\n",
    "```python\n",
    "tensor([[1.1406, 1.2201, 1.9098],\n",
    "        [1.7349, 1.1998, 1.6482],\n",
    "        [1.6419, 1.3224, 1.9947],\n",
    "        [1.4533, 1.3280, 1.2317],\n",
    "        [1.6811, 1.5898, 1.2982]])\n",
    "tensor([[2.1406, 2.2201, 2.9098],\n",
    "        [2.7349, 2.1998, 2.6482],\n",
    "        [2.6419, 2.3224, 2.9947],\n",
    "        [2.4533, 2.3280, 2.2317],\n",
    "        [2.6811, 2.5898, 2.2982]])\n",
    "```\n",
    "\n",
    "如果需要克隆，可以用：\n",
    "```python\n",
    "y=x.clone()\n",
    "```\n",
    "下面会提到转换数据shape的函数：view，也是共享data的\n",
    "\n",
    "**注：虽然view返回的Tensor与源Tensor是共享data的，但是依然是一个新的Tensor（因为Tensor除了包含data外还有一些其他属性），二者id（内存地址）并不一致。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "organizational-kingston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6419, 2.3224],\n",
       "        [2.4533, 2.3280],\n",
       "        [2.6811, 2.5898]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 索引,数组切片\n",
    "x[2:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "signed-matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1406, 2.2201, 2.9098, 2.7349, 2.1998, 2.6482, 2.6419, 2.3224, 2.9947,\n",
      "        2.4533, 2.3280, 2.2317, 2.6811, 2.5898, 2.2982])\n",
      "tensor([[2.1406, 2.2201, 2.9098, 2.7349, 2.1998],\n",
      "        [2.6482, 2.6419, 2.3224, 2.9947, 2.4533],\n",
      "        [2.3280, 2.2317, 2.6811, 2.5898, 2.2982]])\n"
     ]
    }
   ],
   "source": [
    "# view改变形状\n",
    "\n",
    "print(x.view(15))\n",
    "print(x.view(-1, 5))  # -1所指的维度可以根据其他维度的值推出来\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-bottle",
   "metadata": {},
   "source": [
    "** 这里view同上，只是改变了数据的排列方式。**\n",
    "** 因此如果赋值后也会是赋内存地址，改变后源数据也会改变 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "plastic-giving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1406, 0.2201, 0.9098],\n",
      "        [0.7349, 0.1998, 0.6482],\n",
      "        [0.6419, 0.3224, 0.9947],\n",
      "        [0.4533, 0.3280, 0.2317],\n",
      "        [0.6811, 0.5898, 0.2982]])\n",
      "0.14061522483825684\n"
     ]
    }
   ],
   "source": [
    "# tensor转换为number\n",
    "print(x)\n",
    "print(x[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "oriented-riverside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [0]])\n",
      "tensor([[1, 2],\n",
      "        [2, 3],\n",
      "        [1, 2]])\n",
      "tensor([[1, 2],\n",
      "        [2, 3],\n",
      "        [1, 2]])\n"
     ]
    }
   ],
   "source": [
    "#broadcast机制\n",
    "#如果x和y数组的维度不同，则触发broadcast机制完成运算\n",
    "\n",
    "x=torch.tensor([1,2])\n",
    "y=torch.tensor([[0],[1],[0],])\n",
    "print(x)\n",
    "print(y)\n",
    "print(x+y)\n",
    "\n",
    "print(torch.tensor([[1,2],[1,2],[1,2]])\n",
    "      +torch.tensor([[0,0],[1,1],[0,0]]))\n",
    "# x="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "wrong-circus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]\n",
      "tensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "# tensor和numpy也是共享data的\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a, b)\n",
    "\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "pharmaceutical-asset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "[3. 3. 3. 3. 3.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
      "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# torch_from_numpy()可以把numpy转tensor\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a, b)\n",
    "\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)\n",
    "\n",
    "# 如果使用torch.tensor函数，会把数据拷贝，不会共享data\n",
    "a=np.ones(5)\n",
    "b=torch.tensor(a)\n",
    "print(a, b)\n",
    "\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "large-baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tensor([2, 3], device='cuda:0')\n",
      "tensor([2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#to可以把数据从cpu移动到GPU?\n",
    "# 平常我们会这么操作？\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # GPU\n",
    "    print(device)\n",
    "    y = torch.ones_like(x, device=device)  # 直接创建一个在GPU上的Tensor\n",
    "    x = x.to(device)                       # 等价于 .to(\"cuda\")\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # to()还可以同时更改数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thrown-missouri",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.zeros(5,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
