{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "```python\n",
    "1. torch.arange: generate increasing sequence, return \"tensor\"\n",
    "\n",
    "2. tensor.shape: shape\n",
    "3. tensor.numel:\n",
    "3. tensor.reshape(others,row,col)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "torch.Size([12])\n",
      "12\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "torch.Size([3, 4])\n",
      "<built-in method numel of Tensor object at 0x7f6ffe0a7e00>\n",
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.7624, 0.7603],\n",
      "        [0.7381, 0.9149]])\n",
      "tensor([[ 0.5657, -0.8454],\n",
      "        [ 1.0570, -1.2559]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.arange(12)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.numel())\n",
    "X=x.reshape(3,4)\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(X.numel)\n",
    "print(torch.zeros((2,3,4)))\n",
    "print(torch.ones(2,2))\n",
    "print(torch.rand(2,2))\n",
    "print(torch.randn(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]),\n",
       " tensor([ 2.,  4.,  8., 16.]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 运算\n",
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "x + y, x - y, x * y, x / y, x ** y, x*y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4])\n",
      "torch.Size([3, 8])\n"
     ]
    }
   ],
   "source": [
    "# cat的意思可以理解为加和某一个轴的元素\n",
    "print(torch.cat((X,Y),dim=0).shape)\n",
    "print(torch.cat((X,Y),dim=1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## broadcasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=a+b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor([1, 2, 3]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 切片在这里也可用\n",
    "c[0,-1],c[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .item转换成python标量\n",
    "c[0,0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 数据预处理\n",
    "pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/house_tiny.csv\",\"w\") as f:\n",
    "    f.write('NumRooms,Alley,Price\\n')  # 列名\n",
    "    f.write('NA,Pave,127500\\n')  # 每行表示一个数据样本\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"./data/house_tiny.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley\n",
      "0       3.0  Pave\n",
      "1       2.0   NaN\n",
      "2       4.0   NaN\n",
      "3       3.0   NaN\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       3.0           1          0\n",
      "1       2.0           0          1\n",
      "2       4.0           0          1\n",
      "3       3.0           0          1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 1., 0.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 0., 1.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500, 106000, 178100, 140000]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas转tensor\n",
    "import torch\n",
    "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 线性代数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.]), tensor([6.]), tensor([1.5000]), tensor([9.]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标量\n",
    "x = torch.tensor([3.0])\n",
    "y = torch.tensor([2.0])\n",
    "\n",
    "x + y, x * y, x / y, x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向量，标里的列表\n",
    "x = torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 长度=维度，多维叫形状\n",
    "len(x),x.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    return 3 * x ** 2 - 4 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h=0.10000, numerical limit=2.30000\n",
      "h=0.01000, numerical limit=2.03000\n",
      "h=0.00100, numerical limit=2.00300\n",
      "h=0.00010, numerical limit=2.00030\n",
      "h=0.00001, numerical limit=2.00003\n"
     ]
    }
   ],
   "source": [
    "def numerical_lim(f, x, h):\n",
    "    return (f(x + h) - f(x)) / h\n",
    "\n",
    "h = 0.1\n",
    "for i in range(5):\n",
    "    print(f'h={h:.5f}, numerical limit={numerical_lim(f, 1, h):.5f}')\n",
    "    h *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'plt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-88a8aca9e138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f(x)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f(x)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Tangent line (x=1)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-102-88a8aca9e138>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(X, Y, xlabel, ylabel, legend, xlim, ylim, xscale, yscale, fmts, figsize, axes)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mlegend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mset_figsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-88a8aca9e138>\u001b[0m in \u001b[0;36mset_figsize\u001b[0;34m(figsize)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m\"\"\"设置matplotlib的图表大小。\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0muse_svg_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mset_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'plt'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "def use_svg_display():  #@save\n",
    "    \"\"\"使用svg格式在Jupyter中显示绘图。\"\"\"\n",
    "    display.set_matplotlib_formats('svg')\n",
    "    \n",
    "def set_figsize(figsize=(3.5, 2.5)):  #@save\n",
    "    \"\"\"设置matplotlib的图表大小。\"\"\"\n",
    "    use_svg_display()\n",
    "    d2l.plt.rcParams['figure.figsize'] = figsize\n",
    "    \n",
    "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "    \"\"\"设置matplotlib的轴。\"\"\"\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_xscale(xscale)\n",
    "    axes.set_yscale(yscale)\n",
    "    axes.set_xlim(xlim)\n",
    "    axes.set_ylim(ylim)\n",
    "    if legend:\n",
    "        axes.legend(legend)\n",
    "    axes.grid()\n",
    "    \n",
    "#@save\n",
    "def plot(X, Y=None, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "         ylim=None, xscale='linear', yscale='linear',\n",
    "         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n",
    "    \"\"\"绘制数据点。\"\"\"\n",
    "    if legend is None:\n",
    "        legend = []\n",
    "\n",
    "    set_figsize(figsize)\n",
    "    axes = axes if axes else d2l.plt.gca()\n",
    "\n",
    "    # 如果 `X` 有一个轴，输出True\n",
    "    def has_one_axis(X):\n",
    "        return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list)\n",
    "                and not hasattr(X[0], \"__len__\"))\n",
    "\n",
    "    if has_one_axis(X):\n",
    "        X = [X]\n",
    "    if Y is None:\n",
    "        X, Y = [[]] * len(X), X\n",
    "    elif has_one_axis(Y):\n",
    "        Y = [Y]\n",
    "    if len(X) != len(Y):\n",
    "        X = X * len(Y)\n",
    "    axes.cla()\n",
    "    for x, y, fmt in zip(X, Y, fmts):\n",
    "        if len(x):\n",
    "            axes.plot(x, y, fmt)\n",
    "        else:\n",
    "            axes.plot(y, fmt)\n",
    "    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "    \n",
    "x = np.arange(0, 3, 0.1)\n",
    "plot(x, [f(x), 2 * x - 3], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 自动求导\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(4.0,requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.requires_grad_(True)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 2 * torch.dot(x, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1502, requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(size=(), requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-123006.9688, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = f(a)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad == d/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2473, requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(size=(),requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.9147, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=a*2\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Bernoulli in module torch.distributions.bernoulli:\n",
      "\n",
      "class Bernoulli(torch.distributions.exp_family.ExponentialFamily)\n",
      " |  Bernoulli(probs=None, logits=None, validate_args=None)\n",
      " |  \n",
      " |  Creates a Bernoulli distribution parameterized by :attr:`probs`\n",
      " |  or :attr:`logits` (but not both).\n",
      " |  \n",
      " |  Samples are binary (0 or 1). They take the value `1` with probability `p`\n",
      " |  and `0` with probability `1 - p`.\n",
      " |  \n",
      " |  Example::\n",
      " |  \n",
      " |      >>> m = Bernoulli(torch.tensor([0.3]))\n",
      " |      >>> m.sample()  # 30% chance 1; 70% chance 0\n",
      " |      tensor([ 0.])\n",
      " |  \n",
      " |  Args:\n",
      " |      probs (Number, Tensor): the probability of sampling `1`\n",
      " |      logits (Number, Tensor): the log-odds of sampling `1`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Bernoulli\n",
      " |      torch.distributions.exp_family.ExponentialFamily\n",
      " |      torch.distributions.distribution.Distribution\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, probs=None, logits=None, validate_args=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  entropy(self)\n",
      " |      Method to compute the entropy using Bregman divergence of the log normalizer.\n",
      " |  \n",
      " |  enumerate_support(self, expand=True)\n",
      " |      Returns tensor containing all values supported by a discrete\n",
      " |      distribution. The result will enumerate over dimension 0, so the shape\n",
      " |      of the result will be `(cardinality,) + batch_shape + event_shape`\n",
      " |      (where `event_shape = ()` for univariate distributions).\n",
      " |      \n",
      " |      Note that this enumerates over all batched tensors in lock-step\n",
      " |      `[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\n",
      " |      along dim 0, but with the remaining batch dimensions being\n",
      " |      singleton dimensions, `[[0], [1], ..`.\n",
      " |      \n",
      " |      To iterate over the full Cartesian product use\n",
      " |      `itertools.product(m.enumerate_support())`.\n",
      " |      \n",
      " |      Args:\n",
      " |          expand (bool): whether to expand the support over the\n",
      " |              batch dims to match the distribution's `batch_shape`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tensor iterating over dimension 0.\n",
      " |  \n",
      " |  expand(self, batch_shape, _instance=None)\n",
      " |      Returns a new distribution instance (or populates an existing instance\n",
      " |      provided by a derived class) with batch dimensions expanded to\n",
      " |      `batch_shape`. This method calls :class:`~torch.Tensor.expand` on\n",
      " |      the distribution's parameters. As such, this does not allocate new\n",
      " |      memory for the expanded distribution instance. Additionally,\n",
      " |      this does not repeat any args checking or parameter broadcasting in\n",
      " |      `__init__.py`, when an instance is first created.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch_shape (torch.Size): the desired expanded size.\n",
      " |          _instance: new instance provided by subclasses that\n",
      " |              need to override `.expand`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          New distribution instance with batch dimensions expanded to\n",
      " |          `batch_size`.\n",
      " |  \n",
      " |  log_prob(self, value)\n",
      " |      Returns the log of the probability density/mass function evaluated at\n",
      " |      `value`.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (Tensor):\n",
      " |  \n",
      " |  logits(...)\n",
      " |  \n",
      " |  probs(...)\n",
      " |  \n",
      " |  sample(self, sample_shape=torch.Size([]))\n",
      " |      Generates a sample_shape shaped sample or sample_shape shaped batch of\n",
      " |      samples if the distribution parameters are batched.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  mean\n",
      " |      Returns the mean of the distribution.\n",
      " |  \n",
      " |  param_shape\n",
      " |  \n",
      " |  variance\n",
      " |      Returns the variance of the distribution.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0...\n",
      " |  \n",
      " |  has_enumerate_support = True\n",
      " |  \n",
      " |  support = Boolean()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  cdf(self, value)\n",
      " |      Returns the cumulative density/mass function evaluated at\n",
      " |      `value`.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (Tensor):\n",
      " |  \n",
      " |  icdf(self, value)\n",
      " |      Returns the inverse cumulative density/mass function evaluated at\n",
      " |      `value`.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (Tensor):\n",
      " |  \n",
      " |  perplexity(self)\n",
      " |      Returns perplexity of distribution, batched over batch_shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tensor of shape batch_shape.\n",
      " |  \n",
      " |  rsample(self, sample_shape=torch.Size([]))\n",
      " |      Generates a sample_shape shaped reparameterized sample or sample_shape\n",
      " |      shaped batch of reparameterized samples if the distribution parameters\n",
      " |      are batched.\n",
      " |  \n",
      " |  sample_n(self, n)\n",
      " |      Generates n samples or n batches of samples if the distribution\n",
      " |      parameters are batched.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  set_default_validate_args(value)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  batch_shape\n",
      " |      Returns the shape over which parameters are batched.\n",
      " |  \n",
      " |  event_shape\n",
      " |      Returns the shape of a single sample (without batching).\n",
      " |  \n",
      " |  stddev\n",
      " |      Returns the standard deviation of the distribution.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  has_rsample = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.distributions.Bernoulli)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
